{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498e3ce3",
   "metadata": {},
   "source": [
    "# Hi :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eaff15",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b01f20",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66509c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from scipy.stats import mode\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c72f8f",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b70623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "class CNNFeatureDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X= torch.tensor(X, dtype= torch.float32)\n",
    "        self.y= torch.tensor(y, dtype= torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Define 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.network= nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size= 2),  # output: [batch, 16, 2]\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # [batch, 16 * 2]\n",
    "            nn.Linear(16 * 2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  # Binary classification (output: logits for 2 classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b3a171",
   "metadata": {},
   "source": [
    "# ITG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a16a6",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7dae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITG_features_df= pd.read_csv('Dataset/ITG_features_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e28b1",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Train first model (SVM)\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred1 = svm.predict(X_train)\n",
    "errors1 = (y_pred1 != y_train).astype(int)\n",
    "\n",
    "# Step 2: Reweight dataset (more weight on misclassified)\n",
    "weights2 = np.where(errors1 == 1, 2, 1)  # double weight for misclassified\n",
    "indices2 = np.random.choice(len(X_train), size=len(X_train), p=weights2 / weights2.sum())\n",
    "\n",
    "X_train2, y_train2 = X_train[indices2], y_train[indices2]\n",
    "\n",
    "# Step 3: Train second model (Random Forest)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train2, y_train2)\n",
    "y_pred2 = rf.predict(X_train)\n",
    "errors2 = (y_pred2 != y_train).astype(int)\n",
    "\n",
    "# Step 4: Reweight again\n",
    "weights3 = np.where(errors2 == 1, 2, 1)\n",
    "indices3 = np.random.choice(len(X_train), size=len(X_train), p=weights3 / weights3.sum())\n",
    "\n",
    "X_train3, y_train3 = X_train[indices3], y_train[indices3]\n",
    "\n",
    "# Step 5: Train third model (XGBoost)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train3, y_train3)\n",
    "\n",
    "# Final prediction: majority vote from all models\n",
    "\n",
    "\n",
    "# Get predictions on test set\n",
    "pred1 = svm.predict(X_test)\n",
    "pred2 = rf.predict(X_test)\n",
    "pred3 = xgb.predict(X_test)\n",
    "\n",
    "# Combine predictions\n",
    "final_preds = np.array([pred1, pred2, pred3])\n",
    "y_final = mode(final_preds, axis=0).mode.flatten()\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_final))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_final))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_final)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title(\"Manual Boosting - Majority Vote Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qvenv",
   "language": "python",
   "name": "qvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
