{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e95f7ba",
   "metadata": {},
   "source": [
    "# Hi :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc028f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7930d",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b499d9",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f299886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "scaler= StandardScaler()\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class CNNFeatureDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X= torch.tensor(X, dtype= torch.float32)\n",
    "        self.y= torch.tensor(y, dtype= torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Define 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.network= nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size= 2),  # output: [batch, 16, 2]\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # [batch, 16 * 2]\n",
    "            nn.Linear(16 * 2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)  # Binary classification (output: logits for 2 classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594da669",
   "metadata": {},
   "source": [
    "# ITG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbb562",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79727c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITG_features_df= pd.read_csv('Dataset/ITG_features_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d36899",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5153bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract features and labels\n",
    "X= ITG_features_df[['F1_sum_vector_magnitude', 'F2_orientation_angle', 'F3_std_magnitude']].values\n",
    "y= ITG_features_df['Situation'].values\n",
    "\n",
    "# Step 2: Encode labels ('Fall' → 1, 'Not Fall' → 0)\n",
    "label_encoder= LabelEncoder()\n",
    "y_encoded= label_encoder.fit_transform(y)\n",
    "\n",
    "# Step 3: Split dataset\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y_encoded, test_size= 0.2, random_state= 48, stratify= y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d69502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c62bc",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: SVM\n",
    "svm= SVC(kernel='rbf', C= 100, gamma= 1, random_state= 48)\n",
    "svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbacd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -- Model 2: Random Forest --\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=48)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# -- Model 3: XGBoost --\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1,\n",
    "                    subsample=0.8, use_label_encoder=False, eval_metric='logloss', random_state=48)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# -- Model 4: CNN --\n",
    "X_cnn_train = scaler.fit_transform(X_train)\n",
    "X_cnn_test = scaler.transform(X_test)\n",
    "X_cnn_train = X_cnn_train.reshape(X_cnn_train.shape[0], 1, X_cnn_train.shape[1])\n",
    "X_cnn_test = X_cnn_test.reshape(X_cnn_test.shape[0], 1, X_cnn_test.shape[1])\n",
    "\n",
    "train_loader = DataLoader(CNNFeatureDataset(X_cnn_train, y_train), batch_size=16, shuffle=True)\n",
    "model_cnn = SimpleCNN(X_cnn_train.shape[2])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_cnn.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_cnn.parameters(), lr=0.001)\n",
    "\n",
    "model_cnn.train()\n",
    "for epoch in range(20):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_cnn(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# === 4. Generate Meta-Features ===\n",
    "def get_predictions(model, X):\n",
    "    if isinstance(model, nn.Module):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "            outputs = model(X_tensor).cpu().numpy()\n",
    "            return outputs\n",
    "    else:\n",
    "        return model.predict_proba(X)\n",
    "\n",
    "# For CNN, use reshaped data\n",
    "X_train_preds = np.column_stack([\n",
    "    svm.predict_proba(X_train_scaled),\n",
    "    rf.predict_proba(X_train),\n",
    "    xgb.predict_proba(X_train),\n",
    "    get_predictions(model_cnn, X_cnn_train)\n",
    "])\n",
    "\n",
    "X_test_preds = np.column_stack([\n",
    "    svm.predict_proba(X_test_scaled),\n",
    "    rf.predict_proba(X_test),\n",
    "    xgb.predict_proba(X_test),\n",
    "    get_predictions(model_cnn, X_cnn_test)\n",
    "])\n",
    "\n",
    "# === 5. Train Meta-Model ===\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_train_preds, y_train)\n",
    "final_preds = meta_model.predict(X_test_preds)\n",
    "\n",
    "# === 6. Evaluate ===\n",
    "acc = accuracy_score(y_test, final_preds)\n",
    "print(f\"Stacking Ensemble Accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qvenv",
   "language": "python",
   "name": "qvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
